<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ai on Личный сайт Ивана Белашкина</title><link>https://tookser.github.io/tags/ai/</link><description>Recent content in ai on Личный сайт Ивана Белашкина</description><generator>Hugo -- gohugo.io</generator><language>ru-ru</language><lastBuildDate>Mon, 16 Jun 2025 23:13:12 +0300</lastBuildDate><atom:link href="https://tookser.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Мой третий хакатон (отчёт по хакатону ogon.ai - MCP)</title><link>https://tookser.github.io/posts/hackathon2/</link><pubDate>Mon, 16 Jun 2025 23:13:12 +0300</pubDate><guid>https://tookser.github.io/posts/hackathon2/</guid><description>Сначала будет отчёт по хакатону, с описанием &amp;ldquo;как это было и чувствовалось&amp;rdquo;. Во второй части — про инструменты которые я впервые потыкал.
Отчёт Изначально прочитал об идее этого онлайн-хакатон, и сразу подумал &amp;ldquo;круто, как раз про mcp, можно будет потыкать!&amp;rdquo;. И когда понял, что собирается команда, решил присоединиться.
Хакатон - это стартап в миниатюре.
Мы начали &amp;ldquo;хакатонить&amp;rdquo; в четверг, хотя можно было раньше, а закончили в понедельник, вечером, в 22:59.</description><content>&lt;p>Сначала будет отчёт по хакатону, с описанием &amp;ldquo;как это было и чувствовалось&amp;rdquo;. Во второй части — про инструменты которые я впервые потыкал.&lt;/p>
&lt;h2 id="отчёт">Отчёт&lt;/h2>
&lt;p>Изначально прочитал об идее этого онлайн-хакатон, и сразу подумал &amp;ldquo;круто, как раз про mcp, можно будет потыкать!&amp;rdquo;. И когда понял, что собирается команда, решил присоединиться.&lt;/p>
&lt;blockquote>
&lt;p>Хакатон - это стартап в миниатюре.&lt;/p>
&lt;/blockquote>
&lt;p>Мы начали &amp;ldquo;хакатонить&amp;rdquo; в четверг, хотя можно было раньше, а закончили в понедельник, вечером, в 22:59.&lt;/p>
&lt;p>У нас был продакт, 3 бэкендера (включая меня) и 1 фронтэндер. Мне очень понравилось, что на этом хакатоне у нас был продакт, с опытом хакатона в роли продакта, и что идея была вполне годная. Мне понравилось взаимодействие в команде.&lt;/p>
&lt;p>Организация работ выглядела как 2 созвона-&amp;ldquo;синка&amp;rdquo; в день, утром и вечером, со списком задач на &amp;ldquo;до следующего созвона&amp;rdquo;. По некоторым штукам нужно было контактировать с другими программистами. Учёт фич и багов, а также взаимодействия с организатором хакатона — взял на себя продакт.&lt;/p>
&lt;p>Вообще с самого начала думал, что идея будет хорошей, и реализация достаточно простой. Оказалось что так и есть, и приложение стало нам всерьёз нравиться. Да, есть что допиливать (во всех местах, наверное). Но&amp;hellip;&lt;/p>
&lt;blockquote>
&lt;p>Добавление кардинально новой функциональности — это маленький pivot&lt;/p>
&lt;/blockquote>
&lt;p>У нас было два таких момента:&lt;/p>
&lt;ol>
&lt;li>Когда мы решили делать бекенд на &lt;code>n8n&lt;/code> (это было довольно хорошее решение; архитектура выглядит довольно симпатичной — мне кажется, поломки были бы неприятнее, если бы бек был на питоне).&lt;/li>
&lt;li>Когда мы решили добавить на фронт и бек ещё одну функциональность, которая является, возможно, ключевой фичей.&lt;/li>
&lt;/ol>
&lt;h3 id="по-дням">По дням&lt;/h3>
&lt;p>День первый — собрались, долго обсудили, я разработал MCP-сервер.
День второй, третий, четвёртый — у меня преимущественно n8n, также тестирование. В 3-4 день много сделал. Забавно, что засев за n8n пайплайн, довольно много переработал.
День пятый — доделали и подготовили к презентации.&lt;/p>
&lt;hr>
&lt;h3 id="что-хорошо">Что хорошо:&lt;/h3>
&lt;ul>
&lt;li>я использовал в принципе многие свои навыки (в тч и те, которые слабые). Кажется, только фронтендом непосредственно не занимался&lt;/li>
&lt;li>я тестировал продукт, он получился прикольный (да, есть что доделать)&lt;/li>
&lt;li>я предлагал и обсуждал фичи&lt;/li>
&lt;li>я работал с бекендом на n8n (1 из 2 воркфлоу)&lt;/li>
&lt;li>я работал с бекендом на Python (MCP-сервер)&lt;/li>
&lt;li>я формулировал требования, если были нечёткие&lt;/li>
&lt;li>я собрал простенький пайплайн для сборки фронтенда, и &lt;code>docker-compose.yml&lt;/code> для запуска моего MCP-сервера.&lt;/li>
&lt;/ul>
&lt;h3 id="что-можно-было-бы-улучшить-с-моей-стороны">Что можно было бы улучшить с моей стороны:&lt;/h3>
&lt;ul>
&lt;li>не пропускать тестирование ключевых фич. Канбан доска с приоритетами, по идее, решает это, но в таких штуках есть обычно много зависимостей которые апдейтятся постоянно.&lt;/li>
&lt;li>иногда впадал в &amp;ldquo;клинч объяснения&amp;rdquo; в устной и &amp;ldquo;письменно-устной&amp;rdquo; (быстрый текст в чате). У меня часто бывают нечёткие формулировки, оговорки в терминологии, это мешает формулировать и мешает другим быстро меня понять. Стоит позаниматься своей речью, когда будут на это ресурсы.&lt;/li>
&lt;li>не затупливать над стереотипными проблемами. Кажется, это вообще что-то очень человеческое — когда одна и та же проблема, с вариациями, повторяется, но время на её исправление тратится почти столько же.&lt;/li>
&lt;/ul>
&lt;h3 id="команда">Команда:&lt;/h3>
&lt;ul>
&lt;li>всё офигенно!&lt;/li>
&lt;li>(мне оч понравилось, правда! спасибо отдельное продакту за организацию, это даже не выглядело хаосом (ну почти))&lt;/li>
&lt;li>возможно, была бы полезна какая-то доска/страница/сообщение с задачами и закреп с важными ссылками в тг-чате (в самом начале мы посидели над миро-доской, но вроде это было разово).&lt;/li>
&lt;/ul>
&lt;h3 id="орги">Орги:&lt;/h3>
&lt;ul>
&lt;li>понятные тексты/правила/требования. Впрочем, ещё не дождался объявления победителей)&lt;/li>
&lt;li>на вопросы по ходу дела отвечали&lt;/li>
&lt;li>консультацию с техническим специалистом дали, было содержательно
&lt;ul>
&lt;li>был момент, когда возникла как бы сама собой (но было подведено предыдущим диалогом) довольно очевидная, но хорошая идея&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>каких-то ресурсов дополнительно выделено не было&lt;/li>
&lt;/ul>
&lt;h2 id="новые-для-меня-инструменты">Новые (для меня) инструменты&lt;/h2>
&lt;h3 id="n8nio">n8n.io&lt;/h3>
&lt;p>&lt;code>n8n&lt;/code> - low-code инструмент.&lt;/p>
&lt;ul>
&lt;li>Плюсы: довольно простой, есть много разных нод, включая ИИ-шные.&lt;/li>
&lt;li>Эстетичный, логичный интерфейс.&lt;/li>
&lt;li>Опенсорс (важный плюс), хотя есть и премиум версии.&lt;/li>
&lt;li>Есть сообщество, да и документация&lt;/li>
&lt;li>Минусы:
&lt;ul>
&lt;li>селф-хостед версия
&lt;ul>
&lt;li>не содержит общих воркфлоу, в отличие от облачной. Можно редактировать что угодно из-под админского аккаунта, можно всем вместе сидеть из-под одного аккаунта.&lt;/li>
&lt;li>не содержит (кажется) отладки по ходу дела, в отличие от облачной.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>местами очень неприятные баги (ладно, не самые неприятные, но неприятные):
&lt;ul>
&lt;li>один раз я хотел обновить выходной формат ноды. Это была иишная нода, у неё была &lt;a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/#related-resources">доп. нода Structured Output&lt;/a>, чтобы она проверяла формат. Я изменил JSON-схему в ноде, но почему-то вывод выводился то в старом формате, то в новом. По просмотру промта стало понятно, что схема подтягивается старая. Понадобилось, кажется, заново создать Structured Output ноду.&lt;/li>
&lt;li>не удавалось завершить по ошибке запущенный, очень долгий воркфлоу. Нода LLM-ки работала при всех возможных попытках её остановить, выдавала ошибки из-за превышений rate limit. При отключении от основной ноды (агента), она переставала, но при обратном подключении начинала снова. Лечилось аналогично — созданием новой ноды xD&lt;/li>
&lt;li>мелочь, но: есть нода LLM summary, у неё есть режим пересказа по чанкам (старая идея: т.к. текст может быть очень большим, то мы сначала перескажем чанки с пересечением, а потом перескажем все эти пересказы). Если текст полностью влезает в 1 чанк — запроса будет всё равно 2, и это вроде не исправить&amp;hellip; Пришлось избавиться от этой ноды.&lt;/li>
&lt;li>в облачной версии мало ресурсов (сообщают что 300 МБ) и нет поддержки axios/asyncio по умолчанию. На 1ГБ сервере селф-хостед версия грузила почти на 100% RAM и процессор.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="cursor">Cursor&lt;/h3>
&lt;p>&lt;code>Cursor&lt;/code> - AI-powered редактор кода.&lt;/p>
&lt;ul>
&lt;li>Плюсы: ИИ, опенсорс (кроме ИИ-моделей)&lt;/li>
&lt;li>Минусы для меня: VS Code (что непривычно), модели не локальные. Стоит денег))&lt;/li>
&lt;/ul>
&lt;h3 id="mcp-протокол">MCP-протокол&lt;/h3>
&lt;p>MCP — протокол, позволяющий LLM-модели взаимодействовать с внешними инструментами, когда это нужно.&lt;/p>
&lt;ul>
&lt;li>Плюсы:
&lt;ul>
&lt;li>минимальный MCP пишется очень быстро. Я тыкал курсор и MCP некоторое время, а потом стал натыкаться на видео типа &amp;ldquo;Я написал MCP-сервер за 20 минут&amp;rdquo;. so-so&lt;/li>
&lt;li>выполняет мечту &amp;ldquo;дать LLM все инструменты а она уже сама&amp;rdquo;.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Особенности:
&lt;ul>
&lt;li>учитывается как промт LLM-агента, так и промт MCP-сервера (описание предоставляемого им API, по сути). В той библиотеке которую использовал я - докстринг функции-MCP-tool являлся её описанием для бека.
&lt;ul>
&lt;li>при некоторых проблемах&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>есть 3 способа коммуникации, только 2 из них сетевые.&lt;/li>
&lt;li>немного сбивающая терминология — в целом, речь обычно идёт об MCP-клиентах и MCP-серверах, при этом MCP-клиентом могут называть как и программу, использующую сервера (Cursor, Copilot, кастомный LLM-агент&amp;hellip;), так и непосредственно подключение к MCP-серверу.&lt;/li>
&lt;li>ГОВОРЯТ, есть особенности с безопасностью (классической).&lt;/li>
&lt;li>очевидно, есть особенности с безопасностью (которая AI Safety, промт-инъекции): если не контролировать доступ к MCP-server никак, то могут возникнуть проблемы. Есть MCP-сервера для баз данных, например, которые делают к ним запросы.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="system-prompt-generator-чатбот-у-chatgpt">System Prompt Generator (чатбот у ChatGPT)&lt;/h2>
&lt;p>Полезная утилита, позволяющая написать хороший промт (по сути ТЗ) для языковой модели. Выглядит как странный текст, переполненный псевдоMarkdown форматированием и капсом, но работает же. Под конец сам уловил паттерн написания такого и теперь могу писать в таком же стиле.&lt;/p>
&lt;p>&lt;code>Особенность&lt;/code>: Несколько раз замечал, что чатботы работают лучше, когда в самом начале посылается полное ТЗ на желаемый код, а не происходят попытки дополнить во многих сообщениях. С этим чатботом тоже так.&lt;/p></content></item><item><title>MCP - протокол для взаимодействия LLM с сервисами</title><link>https://tookser.github.io/posts/ml_2/</link><pubDate>Wed, 26 Mar 2025 21:35:11 +0300</pubDate><guid>https://tookser.github.io/posts/ml_2/</guid><description>За два дня дважды в разных местах попалось упоминание MCP (Model Context Protocol) (открытая технология Anthropic).
Что это:
https://modelcontextprotocol.io/introduction ссылка на введение в протокол. Может смущать наличие и host, и client, и server: как я понял почитав сайт, основная единица это server, который отвечает на запросы, которые client делает (по указке hostа). https://mcp.so/ тут много примеров MCP. https://habr.com/ru/articles/893482/ - статья про MCP (краткая обзорная часть и примеры кода). См.</description><content>&lt;p>За два дня дважды в разных местах попалось упоминание MCP (Model Context Protocol) (открытая технология Anthropic).&lt;/p>
&lt;p>Что это:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://modelcontextprotocol.io/introduction">https://modelcontextprotocol.io/introduction&lt;/a> ссылка на введение в протокол. Может смущать наличие и host, и client, и server: как я понял почитав сайт, основная единица это server, который отвечает на запросы, которые client делает (по указке hostа).&lt;/li>
&lt;li>&lt;a href="https://mcp.so/">https://mcp.so/&lt;/a> тут много примеров MCP.&lt;/li>
&lt;li>&lt;a href="https://habr.com/ru/articles/893482/">https://habr.com/ru/articles/893482/&lt;/a> - статья про MCP (краткая обзорная часть и примеры кода).&lt;/li>
&lt;/ul>
&lt;p>См. также &lt;a href="https://en.wikipedia.org/wiki/Language_Server_Protocol">LSP&lt;/a> :-) (который во многом похожее делает).&lt;/p>
&lt;p>(С точки зрения AI Safety&amp;hellip; пф-пф-пф. Ну, клиент может обрубать некорректные запросы от хоста. Можно сделать сервер-gateway, который будет ограничивать права в зависимости от).&lt;/p></content></item><item><title>Агентная модель на основе LLM Voyager, действующая в майнкрафте</title><link>https://tookser.github.io/posts/voyager/</link><pubDate>Mon, 07 Oct 2024 12:00:00 +0300</pubDate><guid>https://tookser.github.io/posts/voyager/</guid><description>Under construction.
Сегодня (2024-02-01) просмотрел статью про агент Voyager (код). Идея относительно простая, но захотелось разобраться в деталях.
Модель Voyager на основе LLM GPT-3.5 и GPT-4. Исследует уровень в майнкрафте, с целью &amp;ldquo;как можно больше всего пооткрывать побыстрее&amp;rdquo; (территории и создающиеся предметы).
Есть три модуля.
Планировщик (Automatic Curriculum) Итеративный промтер (Iterative Prompting Mechanism) &amp;ldquo;Словарь&amp;rdquo; навыков (Skill Library) Планировщик - на основе полученных от GPT-V описаний вида сцены (например, лес) и персонажа (json описывающий его инвентарь) генерирует Reasoning (рассуждение какое-то, приводящее к&amp;hellip;) и Task.</description><content>&lt;p>Under construction.&lt;/p>
&lt;p>Сегодня (2024-02-01) просмотрел &lt;a href="https://voyager.minedojo.org">статью про агент Voyager&lt;/a> (&lt;a href="https://github.com/MineDojo/Voyager">код&lt;/a>). Идея относительно простая, но захотелось разобраться в деталях.&lt;/p>
&lt;p>Модель Voyager на основе LLM GPT-3.5 и GPT-4. Исследует уровень в майнкрафте, с целью &amp;ldquo;как можно больше всего пооткрывать побыстрее&amp;rdquo; (территории и создающиеся предметы).&lt;/p>
&lt;p>Есть три модуля.&lt;/p>
&lt;ol>
&lt;li>Планировщик (Automatic Curriculum)&lt;/li>
&lt;li>Итеративный промтер (Iterative Prompting Mechanism)&lt;/li>
&lt;li>&amp;ldquo;Словарь&amp;rdquo; навыков (Skill Library)&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Планировщик - на основе полученных от GPT-V описаний вида сцены (например, лес) и персонажа (json описывающий его инвентарь) генерирует Reasoning (рассуждение какое-то, приводящее к&amp;hellip;) и Task.
&lt;ul>
&lt;li>Task - задача, что нужно сделать. Далее это передаётся словарю навыков.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Словарь навыков как-то формируется.
&lt;ul>
&lt;li>Потом по запросу из него выбирается один из навыков, который является программой, и запускается.&lt;/li>
&lt;li>Комбинирование и появление навыков наименее понимаю. Используется feedback от среды, опять же в текстовом виде.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Итеративный промтер как-то генерирует новые промты.
&lt;ul>
&lt;li>Видимо, к предыдущему: мы видим ошибки от кода выполняемого, соответственно понимаем что пришло к успеху и что нет.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>Картиночки в статье красивые, есть код :)&lt;/p>
&lt;h4 id="см-также">См. также:&lt;/h4>
&lt;ul>
&lt;li>&lt;a href="https://github.com/yoheinakajima/babyagi">BabyAGI&lt;/a>&lt;/li>
&lt;li>ChaosGPT - что-то вроде BabyAGI, только с изначально деструктивными промтами (не одобряю, но задумка на текущем уровне - как высечь море, что-то такое).&lt;/li>
&lt;/ul></content></item><item><title>Промт-инъекция, видео Карпатого и пара быстрых моделей</title><link>https://tookser.github.io/posts/neural1/</link><pubDate>Sun, 10 Mar 2024 20:36:38 +0300</pubDate><guid>https://tookser.github.io/posts/neural1/</guid><description>Начал проходить курс &amp;ldquo;AI Safety fundamentals&amp;rdquo;, и там есть видео Андрея Карпатого про LLM. Больше половины инфы оттуда я знал, но:
идея про то, что языковые модели как класс программ ведут себя аналогично операционным системам (LLM OS). Подробности по ссылке (видео на английском). там очень классное описание возможных атак на LLM (промт-инъекций и не только), со ссылками на статьи. Понятно, что это всё прикрывается достаточно быстро. Jailbroken: How Does LLM Safety Training Fail?</description><content>&lt;p>Начал проходить курс &amp;ldquo;AI Safety fundamentals&amp;rdquo;, и там есть &lt;a href="https://www.youtube.com/watch?v=zjkBMFhNj_g">видео Андрея Карпатого про LLM&lt;/a>. Больше половины инфы оттуда я знал, но:&lt;/p>
&lt;ul>
&lt;li>идея про то, что языковые модели как класс программ ведут себя аналогично операционным системам (&lt;em>LLM OS&lt;/em>). Подробности по &lt;a href="https://www.youtube.com/watch?v=zjkBMFhNj_g&amp;amp;t=2535s">ссылке&lt;/a> (видео на английском).&lt;/li>
&lt;li>там очень классное описание возможных атак на LLM (промт-инъекций и не только), со ссылками на статьи. Понятно, что это всё прикрывается достаточно быстро.
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/2307.02483">Jailbroken: How Does LLM Safety Training Fail?&lt;/a>
&lt;ul>
&lt;li>оттуда, например - про base64 кодирование как метод обхода. LLM умеют читать base64, но не защищены.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>ещё пара статей про отдельные виды атак &lt;a href="https://www.youtube.com/watch?v=zjkBMFhNj_g&amp;amp;t=2743s">(ссылка с таймкодом на последнюю часть видео про это)&lt;/a>, в том числе на мультимодальные модели.&lt;/li>
&lt;li>&lt;a href="https://arxiv.org/abs/2307.15043">Universal and Transferable Adversarial Attacks on Aligned Language Models&lt;/a> - про универсальный, выглядящий набором мусора промт-суффикс. Это надо смотреть.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="пара-ныне-недоступных-быстрых-моделей">Пара (ныне недоступных) быстрых моделей&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.ixbt.com/news/2024/02/20/nikomu-neizvestnyj-startap-groq-predstavil-vidimo-luchshij-processor-dlja-vyvoda-nejrosetevyh-modelej.html">Groq (ixbt)&lt;/a> - ASIC (специализированная микросхема) для быстрого инференса LLM. Потыкать можно &lt;a href="https://groq.com">тут,&lt;/a> (там Llama, Mistral, есть платное АПИ), это впечатляет скоростью. В какой-то момент без прокси перестало быть доступным.&lt;/li>
&lt;li>&lt;a href="https://fastsdxl.ai">https://fastsdxl.ai&lt;/a> - это быстрая генерация картинок, со скоростью ввода. Скорость достигнута в т.ч. благодаря использованию маленькой модели SD XL Lightning. Сейчас недоступна, &lt;strong>обещают вернуться.&lt;/strong>&lt;/li>
&lt;/ul></content></item><item><title>Машинное обучение, ссылки (1)</title><link>https://tookser.github.io/posts/ml_1/</link><pubDate>Sat, 18 Mar 2023 03:21:05 +0300</pubDate><guid>https://tookser.github.io/posts/ml_1/</guid><description>Немного книг, ссылок и сервисов про ML.
Николенко, Введение в глубокое обучение. Написано местами многословно, но увлекательно, с другой стороны - сложные вещи требуют дополнительного гуглинга. Тензорфлоу там используется согласно сети старый, поэтому на него внимательно не смотрел. https://www.deeplearningbook.org/ (англ.) от Goodfellow с соавторами. Пока не смотрел, возможно также, не скачивается в удобном виде. Лекции и семинары Евгения Соколова (ВШЭ). Классика (15 часов) и глубокое обучение (72*1.5 часа), рекомендовались как хорошие видео с понятными объяснениями.</description><content>&lt;p>Немного книг, ссылок и сервисов про ML.&lt;/p>
&lt;ol>
&lt;li>Николенко, Введение в глубокое обучение. Написано местами многословно, но увлекательно, с другой стороны - сложные вещи требуют дополнительного гуглинга. Тензорфлоу там используется согласно сети старый, поэтому на него внимательно не смотрел.&lt;/li>
&lt;li>&lt;a href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/&lt;/a> (англ.) от Goodfellow с соавторами. Пока не смотрел, возможно также, не скачивается в удобном виде.&lt;/li>
&lt;li>Лекции и семинары Евгения Соколова (ВШЭ). &lt;a href="https://www.youtube.com/playlist?list=PLEqoHzpnmTfChItexxg2ZfxCsm-8QPsdS">Классика (15 часов)&lt;/a> и &lt;a href="https://www.youtube.com/playlist?list=PLEwK9wdS5g0qa3PIhR6HBDJD_QnrfP8Ei">глубокое обучение (72*1.5 часа)&lt;/a>, рекомендовались как хорошие видео с понятными объяснениями.&lt;/li>
&lt;/ol>
&lt;p>Мелочи.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://zhang-yang.medium.com/how-pytorch-tensors-backward-accumulates-gradient-8d1bf675579b">Статья на медиуме&lt;/a> про autograd в pytorch. См. также немного &lt;a href="https://stackoverflow.com/questions/62067400/understanding-accumulated-gradients-in-pytorch">на SO&lt;/a>.&lt;/li>
&lt;li>&lt;a href="https://open-assistant.io/ru">https://open-assistant.io/ru&lt;/a>, было бы здорово к этому движу присоединиться.&lt;/li>
&lt;li>Боты по типу ChatGPT, но в ТГ:
&lt;ul>
&lt;li>&lt;a href="https://t.me/talkgptbot">https://t.me/talkgptbot&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://t.me/gpt3_unlim_chatbot">https://t.me/gpt3_unlim_chatbot&lt;/a> (не unlim в бесплатной версии)&lt;/li>
&lt;li>&lt;a href="https://t.me/chatGPTwrapperbot">https://t.me/chatGPTwrapperbot&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://t.me/chatgpt_karfly_bot">https://t.me/chatgpt_karfly_bot&lt;/a>&lt;/li>
&lt;li>особняком стоит &lt;a href="https://t.me/VoiceLogBot">https://t.me/VoiceLogBot&lt;/a> - у этого есть конкретное назначение (быть чем-то вроде коуча-дневника, задающим наводящие вопросы на подумать), плюс он принимает голосовые и кружочки (не проверял качество), &lt;del>и безлимитный&lt;/del> небезлимитный(. Чувствую, эта область (psy-боты в ТГ) ещё минимум год будет развиваться.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://huggingface.co/spaces/huggingface/diffuse-the-rest">https://huggingface.co/spaces/huggingface/diffuse-the-rest&lt;/a> inpainting (дорисовывание картинки/скетча), требует также текстовый промт. Иногда выдаёт неинтересное совсем, иногда результат далёк от наброска.&lt;/li>
&lt;/ul></content></item></channel></rss>