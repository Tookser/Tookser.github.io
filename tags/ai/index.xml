<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ai on Личный сайт Ивана Белашкина</title><link>https://tookser.github.io/tags/ai/</link><description>Recent content in ai on Личный сайт Ивана Белашкина</description><generator>Hugo -- gohugo.io</generator><language>ru-ru</language><lastBuildDate>Mon, 07 Oct 2024 12:00:00 +0300</lastBuildDate><atom:link href="https://tookser.github.io/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Агентная модель на основе LLM Voyager, действующая в майнкрафте</title><link>https://tookser.github.io/posts/voyager/</link><pubDate>Mon, 07 Oct 2024 12:00:00 +0300</pubDate><guid>https://tookser.github.io/posts/voyager/</guid><description>Under construction.
Сегодня (2024-02-01) просмотрел статью про агент Voyager (код). Идея относительно простая, но захотелось разобраться в деталях.
Модель Voyager на основе LLM GPT-3.5 и GPT-4. Исследует уровень в майнкрафте, с целью &amp;ldquo;как можно больше всего пооткрывать побыстрее&amp;rdquo; (территории и создающиеся предметы).
Есть три модуля.
Планировщик (Automatic Curriculum) Итеративный промтер (Iterative Prompting Mechanism) &amp;ldquo;Словарь&amp;rdquo; навыков (Skill Library) Планировщик - на основе полученных от GPT-V описаний вида сцены (например, лес) и персонажа (json описывающий его инвентарь) генерирует Reasoning (рассуждение какое-то, приводящее к&amp;hellip;) и Task.</description><content>&lt;p>Under construction.&lt;/p>
&lt;p>Сегодня (2024-02-01) просмотрел &lt;a href="https://voyager.minedojo.org">статью про агент Voyager&lt;/a> (&lt;a href="https://github.com/MineDojo/Voyager">код&lt;/a>). Идея относительно простая, но захотелось разобраться в деталях.&lt;/p>
&lt;p>Модель Voyager на основе LLM GPT-3.5 и GPT-4. Исследует уровень в майнкрафте, с целью &amp;ldquo;как можно больше всего пооткрывать побыстрее&amp;rdquo; (территории и создающиеся предметы).&lt;/p>
&lt;p>Есть три модуля.&lt;/p>
&lt;ol>
&lt;li>Планировщик (Automatic Curriculum)&lt;/li>
&lt;li>Итеративный промтер (Iterative Prompting Mechanism)&lt;/li>
&lt;li>&amp;ldquo;Словарь&amp;rdquo; навыков (Skill Library)&lt;/li>
&lt;/ol>
&lt;ul>
&lt;li>Планировщик - на основе полученных от GPT-V описаний вида сцены (например, лес) и персонажа (json описывающий его инвентарь) генерирует Reasoning (рассуждение какое-то, приводящее к&amp;hellip;) и Task.
&lt;ul>
&lt;li>Task - задача, что нужно сделать. Далее это передаётся словарю навыков.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Словарь навыков как-то формируется.
&lt;ul>
&lt;li>Потом по запросу из него выбирается один из навыков, который является программой, и запускается.&lt;/li>
&lt;li>Комбинирование и появление навыков наименее понимаю. Используется feedback от среды, опять же в текстовом виде.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Итеративный промтер как-то генерирует новые промты.
&lt;ul>
&lt;li>Видимо, к предыдущему: мы видим ошибки от кода выполняемого, соответственно понимаем что пришло к успеху и что нет.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>Картиночки в статье красивые, есть код :)&lt;/p>
&lt;h4 id="см-также">См. также:&lt;/h4>
&lt;ul>
&lt;li>&lt;a href="https://github.com/yoheinakajima/babyagi">BabyAGI&lt;/a>&lt;/li>
&lt;li>ChaosGPT - что-то вроде BabyAGI, только с изначально деструктивными промтами (не одобряю, но задумка на текущем уровне - как высечь море, что-то такое).&lt;/li>
&lt;/ul></content></item><item><title>Промт-инъекция, видео Карпатого и пара быстрых моделей</title><link>https://tookser.github.io/posts/neural1/</link><pubDate>Sun, 10 Mar 2024 20:36:38 +0300</pubDate><guid>https://tookser.github.io/posts/neural1/</guid><description>Начал проходить курс &amp;ldquo;AI Safety fundamentals&amp;rdquo;, и там есть видео Андрея Карпатого про LLM. Больше половины инфы оттуда я знал, но:
идея про то, что языковые модели как класс программ ведут себя аналогично операционным системам (LLM OS). Подробности по ссылке (видео на английском). там очень классное описание возможных атак на LLM (промт-инъекций и не только), со ссылками на статьи. Понятно, что это всё прикрывается достаточно быстро. Jailbroken: How Does LLM Safety Training Fail?</description><content>&lt;p>Начал проходить курс &amp;ldquo;AI Safety fundamentals&amp;rdquo;, и там есть &lt;a href="https://www.youtube.com/watch?v=zjkBMFhNj_g">видео Андрея Карпатого про LLM&lt;/a>. Больше половины инфы оттуда я знал, но:&lt;/p>
&lt;ul>
&lt;li>идея про то, что языковые модели как класс программ ведут себя аналогично операционным системам (&lt;em>LLM OS&lt;/em>). Подробности по &lt;a href="https://www.youtube.com/watch?v=zjkBMFhNj_g&amp;amp;t=2535s">ссылке&lt;/a> (видео на английском).&lt;/li>
&lt;li>там очень классное описание возможных атак на LLM (промт-инъекций и не только), со ссылками на статьи. Понятно, что это всё прикрывается достаточно быстро.
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/2307.02483">Jailbroken: How Does LLM Safety Training Fail?&lt;/a>
&lt;ul>
&lt;li>оттуда, например - про base64 кодирование как метод обхода. LLM умеют читать base64, но не защищены.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>ещё пара статей про отдельные виды атак &lt;a href="https://www.youtube.com/watch?v=zjkBMFhNj_g&amp;amp;t=2743s">(ссылка с таймкодом на последнюю часть видео про это)&lt;/a>, в том числе на мультимодальные модели.&lt;/li>
&lt;li>&lt;a href="https://arxiv.org/abs/2307.15043">Universal and Transferable Adversarial Attacks on Aligned Language Models&lt;/a> - про универсальный, выглядящий набором мусора промт-суффикс. Это надо смотреть.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="пара-ныне-недоступных-быстрых-моделей">Пара (ныне недоступных) быстрых моделей&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.ixbt.com/news/2024/02/20/nikomu-neizvestnyj-startap-groq-predstavil-vidimo-luchshij-processor-dlja-vyvoda-nejrosetevyh-modelej.html">Groq (ixbt)&lt;/a> - ASIC (специализированная микросхема) для быстрого инференса LLM. Потыкать можно &lt;a href="https://groq.com">тут,&lt;/a> (там Llama, Mistral, есть платное АПИ), это впечатляет скоростью. В какой-то момент без прокси перестало быть доступным.&lt;/li>
&lt;li>&lt;a href="https://fastsdxl.ai">https://fastsdxl.ai&lt;/a> - это быстрая генерация картинок, со скоростью ввода. Скорость достигнута в т.ч. благодаря использованию маленькой модели SD XL Lightning. Сейчас недоступна, &lt;strong>обещают вернуться.&lt;/strong>&lt;/li>
&lt;/ul></content></item><item><title>Машинное обучение, ссылки (1)</title><link>https://tookser.github.io/posts/ml_1/</link><pubDate>Sat, 18 Mar 2023 03:21:05 +0300</pubDate><guid>https://tookser.github.io/posts/ml_1/</guid><description>Немного книг, ссылок и сервисов про ML.
Николенко, Введение в глубокое обучение. Написано местами многословно, но увлекательно, с другой стороны - сложные вещи требуют дополнительного гуглинга. Тензорфлоу там используется согласно сети старый, поэтому на него внимательно не смотрел. https://www.deeplearningbook.org/ (англ.) от Goodfellow с соавторами. Пока не смотрел, возможно также, не скачивается в удобном виде. Лекции и семинары Евгения Соколова (ВШЭ). Классика (15 часов) и глубокое обучение (72*1.5 часа), рекомендовались как хорошие видео с понятными объяснениями.</description><content>&lt;p>Немного книг, ссылок и сервисов про ML.&lt;/p>
&lt;ol>
&lt;li>Николенко, Введение в глубокое обучение. Написано местами многословно, но увлекательно, с другой стороны - сложные вещи требуют дополнительного гуглинга. Тензорфлоу там используется согласно сети старый, поэтому на него внимательно не смотрел.&lt;/li>
&lt;li>&lt;a href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/&lt;/a> (англ.) от Goodfellow с соавторами. Пока не смотрел, возможно также, не скачивается в удобном виде.&lt;/li>
&lt;li>Лекции и семинары Евгения Соколова (ВШЭ). &lt;a href="https://www.youtube.com/playlist?list=PLEqoHzpnmTfChItexxg2ZfxCsm-8QPsdS">Классика (15 часов)&lt;/a> и &lt;a href="https://www.youtube.com/playlist?list=PLEwK9wdS5g0qa3PIhR6HBDJD_QnrfP8Ei">глубокое обучение (72*1.5 часа)&lt;/a>, рекомендовались как хорошие видео с понятными объяснениями.&lt;/li>
&lt;/ol>
&lt;p>Мелочи.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://zhang-yang.medium.com/how-pytorch-tensors-backward-accumulates-gradient-8d1bf675579b">Статья на медиуме&lt;/a> про autograd в pytorch. См. также немного &lt;a href="https://stackoverflow.com/questions/62067400/understanding-accumulated-gradients-in-pytorch">на SO&lt;/a>.&lt;/li>
&lt;li>&lt;a href="https://open-assistant.io/ru">https://open-assistant.io/ru&lt;/a>, было бы здорово к этому движу присоединиться.&lt;/li>
&lt;li>Боты по типу ChatGPT, но в ТГ:
&lt;ul>
&lt;li>&lt;a href="https://t.me/talkgptbot">https://t.me/talkgptbot&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://t.me/gpt3_unlim_chatbot">https://t.me/gpt3_unlim_chatbot&lt;/a> (не unlim в бесплатной версии)&lt;/li>
&lt;li>&lt;a href="https://t.me/chatGPTwrapperbot">https://t.me/chatGPTwrapperbot&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://t.me/chatgpt_karfly_bot">https://t.me/chatgpt_karfly_bot&lt;/a>&lt;/li>
&lt;li>особняком стоит &lt;a href="https://t.me/VoiceLogBot">https://t.me/VoiceLogBot&lt;/a> - у этого есть конкретное назначение (быть чем-то вроде коуча-дневника, задающим наводящие вопросы на подумать), плюс он принимает голосовые и кружочки (не проверял качество), &lt;del>и безлимитный&lt;/del> небезлимитный(. Чувствую, эта область (psy-боты в ТГ) ещё минимум год будет развиваться.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="https://huggingface.co/spaces/huggingface/diffuse-the-rest">https://huggingface.co/spaces/huggingface/diffuse-the-rest&lt;/a> inpainting (дорисовывание картинки/скетча), требует также текстовый промт. Иногда выдаёт неинтересное совсем, иногда результат далёк от наброска.&lt;/li>
&lt;/ul></content></item></channel></rss>