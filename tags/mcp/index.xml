<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>mcp on Личный сайт Ивана Белашкина</title><link>https://tookser.github.io/tags/mcp/</link><description>Recent content in mcp on Личный сайт Ивана Белашкина</description><generator>Hugo -- gohugo.io</generator><language>ru-ru</language><lastBuildDate>Mon, 16 Jun 2025 23:13:12 +0300</lastBuildDate><atom:link href="https://tookser.github.io/tags/mcp/index.xml" rel="self" type="application/rss+xml"/><item><title>Мой третий хакатон (отчёт по хакатону ogon.ai - MCP)</title><link>https://tookser.github.io/posts/hackathon2/</link><pubDate>Mon, 16 Jun 2025 23:13:12 +0300</pubDate><guid>https://tookser.github.io/posts/hackathon2/</guid><description>Сначала будет отчёт по хакатону, с описанием &amp;ldquo;как это было и чувствовалось&amp;rdquo;. Во второй части — про инструменты которые я впервые потыкал.
Отчёт Изначально прочитал об идее этого онлайн-хакатон, и сразу подумал &amp;ldquo;круто, как раз про mcp, можно будет потыкать!&amp;rdquo;. И когда понял, что собирается команда, решил присоединиться.
Хакатон - это стартап в миниатюре.
Мы начали &amp;ldquo;хакатонить&amp;rdquo; в четверг, хотя можно было раньше, а закончили в понедельник, вечером, в 22:59.</description><content>&lt;p>Сначала будет отчёт по хакатону, с описанием &amp;ldquo;как это было и чувствовалось&amp;rdquo;. Во второй части — про инструменты которые я впервые потыкал.&lt;/p>
&lt;h2 id="отчёт">Отчёт&lt;/h2>
&lt;p>Изначально прочитал об идее этого онлайн-хакатон, и сразу подумал &amp;ldquo;круто, как раз про mcp, можно будет потыкать!&amp;rdquo;. И когда понял, что собирается команда, решил присоединиться.&lt;/p>
&lt;blockquote>
&lt;p>Хакатон - это стартап в миниатюре.&lt;/p>
&lt;/blockquote>
&lt;p>Мы начали &amp;ldquo;хакатонить&amp;rdquo; в четверг, хотя можно было раньше, а закончили в понедельник, вечером, в 22:59.&lt;/p>
&lt;p>У нас был продакт, 3 бэкендера (включая меня) и 1 фронтэндер. Мне очень понравилось, что на этом хакатоне у нас был продакт, с опытом хакатона в роли продакта, и что идея была вполне годная. Мне понравилось взаимодействие в команде.&lt;/p>
&lt;p>Организация работ выглядела как 2 созвона-&amp;ldquo;синка&amp;rdquo; в день, утром и вечером, со списком задач на &amp;ldquo;до следующего созвона&amp;rdquo;. По некоторым штукам нужно было контактировать с другими программистами. Учёт фич и багов, а также взаимодействия с организатором хакатона — взял на себя продакт.&lt;/p>
&lt;p>Вообще с самого начала думал, что идея будет хорошей, и реализация достаточно простой. Оказалось что так и есть, и приложение стало нам всерьёз нравиться. Да, есть что допиливать (во всех местах, наверное). Но&amp;hellip;&lt;/p>
&lt;blockquote>
&lt;p>Добавление кардинально новой функциональности — это маленький pivot&lt;/p>
&lt;/blockquote>
&lt;p>У нас было два таких момента:&lt;/p>
&lt;ol>
&lt;li>Когда мы решили делать бекенд на &lt;code>n8n&lt;/code> (это было довольно хорошее решение; архитектура выглядит довольно симпатичной — мне кажется, поломки были бы неприятнее, если бы бек был на питоне).&lt;/li>
&lt;li>Когда мы решили добавить на фронт и бек ещё одну функциональность, которая является, возможно, ключевой фичей.&lt;/li>
&lt;/ol>
&lt;h3 id="по-дням">По дням&lt;/h3>
&lt;p>День первый — собрались, долго обсудили, я разработал MCP-сервер.
День второй, третий, четвёртый — у меня преимущественно n8n, также тестирование. В 3-4 день много сделал. Забавно, что засев за n8n пайплайн, довольно много переработал.
День пятый — доделали и подготовили к презентации.&lt;/p>
&lt;hr>
&lt;h3 id="что-хорошо">Что хорошо:&lt;/h3>
&lt;ul>
&lt;li>я использовал в принципе многие свои навыки (в тч и те, которые слабые). Кажется, только фронтендом непосредственно не занимался&lt;/li>
&lt;li>я тестировал продукт, он получился прикольный (да, есть что доделать)&lt;/li>
&lt;li>я предлагал и обсуждал фичи&lt;/li>
&lt;li>я работал с бекендом на n8n (1 из 2 воркфлоу)&lt;/li>
&lt;li>я работал с бекендом на Python (MCP-сервер)&lt;/li>
&lt;li>я формулировал требования, если были нечёткие&lt;/li>
&lt;li>я собрал простенький пайплайн для сборки фронтенда, и &lt;code>docker-compose.yml&lt;/code> для запуска моего MCP-сервера.&lt;/li>
&lt;/ul>
&lt;h3 id="что-можно-было-бы-улучшить-с-моей-стороны">Что можно было бы улучшить с моей стороны:&lt;/h3>
&lt;ul>
&lt;li>не пропускать тестирование ключевых фич. Канбан доска с приоритетами, по идее, решает это, но в таких штуках есть обычно много зависимостей которые апдейтятся постоянно.&lt;/li>
&lt;li>иногда впадал в &amp;ldquo;клинч объяснения&amp;rdquo; в устной и &amp;ldquo;письменно-устной&amp;rdquo; (быстрый текст в чате). У меня часто бывают нечёткие формулировки, оговорки в терминологии, это мешает формулировать и мешает другим быстро меня понять. Стоит позаниматься своей речью, когда будут на это ресурсы.&lt;/li>
&lt;li>не затупливать над стереотипными проблемами. Кажется, это вообще что-то очень человеческое — когда одна и та же проблема, с вариациями, повторяется, но время на её исправление тратится почти столько же.&lt;/li>
&lt;/ul>
&lt;h3 id="команда">Команда:&lt;/h3>
&lt;ul>
&lt;li>всё офигенно!&lt;/li>
&lt;li>(мне оч понравилось, правда! спасибо отдельное продакту за организацию, это даже не выглядело хаосом (ну почти))&lt;/li>
&lt;li>возможно, была бы полезна какая-то доска/страница/сообщение с задачами и закреп с важными ссылками в тг-чате (в самом начале мы посидели над миро-доской, но вроде это было разово).&lt;/li>
&lt;/ul>
&lt;h3 id="орги">Орги:&lt;/h3>
&lt;ul>
&lt;li>понятные тексты/правила/требования. Впрочем, ещё не дождался объявления победителей)&lt;/li>
&lt;li>на вопросы по ходу дела отвечали&lt;/li>
&lt;li>консультацию с техническим специалистом дали, было содержательно
&lt;ul>
&lt;li>был момент, когда возникла как бы сама собой (но было подведено предыдущим диалогом) довольно очевидная, но хорошая идея&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>каких-то ресурсов дополнительно выделено не было&lt;/li>
&lt;/ul>
&lt;h2 id="новые-для-меня-инструменты">Новые (для меня) инструменты&lt;/h2>
&lt;h3 id="n8nio">n8n.io&lt;/h3>
&lt;p>&lt;code>n8n&lt;/code> - low-code инструмент.&lt;/p>
&lt;ul>
&lt;li>Плюсы: довольно простой, есть много разных нод, включая ИИ-шные.&lt;/li>
&lt;li>Эстетичный, логичный интерфейс.&lt;/li>
&lt;li>Опенсорс (важный плюс), хотя есть и премиум версии.&lt;/li>
&lt;li>Есть сообщество, да и документация&lt;/li>
&lt;li>Минусы:
&lt;ul>
&lt;li>селф-хостед версия
&lt;ul>
&lt;li>не содержит общих воркфлоу, в отличие от облачной. Можно редактировать что угодно из-под админского аккаунта, можно всем вместе сидеть из-под одного аккаунта.&lt;/li>
&lt;li>не содержит (кажется) отладки по ходу дела, в отличие от облачной.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>местами очень неприятные баги (ладно, не самые неприятные, но неприятные):
&lt;ul>
&lt;li>один раз я хотел обновить выходной формат ноды. Это была иишная нода, у неё была &lt;a href="https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.outputparserstructured/#related-resources">доп. нода Structured Output&lt;/a>, чтобы она проверяла формат. Я изменил JSON-схему в ноде, но почему-то вывод выводился то в старом формате, то в новом. По просмотру промта стало понятно, что схема подтягивается старая. Понадобилось, кажется, заново создать Structured Output ноду.&lt;/li>
&lt;li>не удавалось завершить по ошибке запущенный, очень долгий воркфлоу. Нода LLM-ки работала при всех возможных попытках её остановить, выдавала ошибки из-за превышений rate limit. При отключении от основной ноды (агента), она переставала, но при обратном подключении начинала снова. Лечилось аналогично — созданием новой ноды xD&lt;/li>
&lt;li>мелочь, но: есть нода LLM summary, у неё есть режим пересказа по чанкам (старая идея: т.к. текст может быть очень большим, то мы сначала перескажем чанки с пересечением, а потом перескажем все эти пересказы). Если текст полностью влезает в 1 чанк — запроса будет всё равно 2, и это вроде не исправить&amp;hellip; Пришлось избавиться от этой ноды.&lt;/li>
&lt;li>в облачной версии мало ресурсов (сообщают что 300 МБ) и нет поддержки axios/asyncio по умолчанию. На 1ГБ сервере селф-хостед версия грузила почти на 100% RAM и процессор.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="cursor">Cursor&lt;/h3>
&lt;p>&lt;code>Cursor&lt;/code> - AI-powered редактор кода.&lt;/p>
&lt;ul>
&lt;li>Плюсы: ИИ, опенсорс (кроме ИИ-моделей)&lt;/li>
&lt;li>Минусы для меня: VS Code (что непривычно), модели не локальные. Стоит денег))&lt;/li>
&lt;/ul>
&lt;h3 id="mcp-протокол">MCP-протокол&lt;/h3>
&lt;p>MCP — протокол, позволяющий LLM-модели взаимодействовать с внешними инструментами, когда это нужно.&lt;/p>
&lt;ul>
&lt;li>Плюсы:
&lt;ul>
&lt;li>минимальный MCP пишется очень быстро. Я тыкал курсор и MCP некоторое время, а потом стал натыкаться на видео типа &amp;ldquo;Я написал MCP-сервер за 20 минут&amp;rdquo;. so-so&lt;/li>
&lt;li>выполняет мечту &amp;ldquo;дать LLM все инструменты а она уже сама&amp;rdquo;.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Особенности:
&lt;ul>
&lt;li>учитывается как промт LLM-агента, так и промт MCP-сервера (описание предоставляемого им API, по сути). В той библиотеке которую использовал я - докстринг функции-MCP-tool являлся её описанием для бека.
&lt;ul>
&lt;li>при некоторых проблемах&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>есть 3 способа коммуникации, только 2 из них сетевые.&lt;/li>
&lt;li>немного сбивающая терминология — в целом, речь обычно идёт об MCP-клиентах и MCP-серверах, при этом MCP-клиентом могут называть как и программу, использующую сервера (Cursor, Copilot, кастомный LLM-агент&amp;hellip;), так и непосредственно подключение к MCP-серверу.&lt;/li>
&lt;li>ГОВОРЯТ, есть особенности с безопасностью (классической).&lt;/li>
&lt;li>очевидно, есть особенности с безопасностью (которая AI Safety, промт-инъекции): если не контролировать доступ к MCP-server никак, то могут возникнуть проблемы. Есть MCP-сервера для баз данных, например, которые делают к ним запросы.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="system-prompt-generator-чатбот-у-chatgpt">System Prompt Generator (чатбот у ChatGPT)&lt;/h2>
&lt;p>Полезная утилита, позволяющая написать хороший промт (по сути ТЗ) для языковой модели. Выглядит как странный текст, переполненный псевдоMarkdown форматированием и капсом, но работает же. Под конец сам уловил паттерн написания такого и теперь могу писать в таком же стиле.&lt;/p>
&lt;p>&lt;code>Особенность&lt;/code>: Несколько раз замечал, что чатботы работают лучше, когда в самом начале посылается полное ТЗ на желаемый код, а не происходят попытки дополнить во многих сообщениях. С этим чатботом тоже так.&lt;/p></content></item></channel></rss>