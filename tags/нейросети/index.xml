<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>нейросети on Личный сайт Ивана Белашкина</title><link>https://tookser.github.io/tags/%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D1%81%D0%B5%D1%82%D0%B8/</link><description>Recent content in нейросети on Личный сайт Ивана Белашкина</description><generator>Hugo -- gohugo.io</generator><language>ru-ru</language><lastBuildDate>Sun, 10 Mar 2024 20:36:38 +0300</lastBuildDate><atom:link href="https://tookser.github.io/tags/%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D1%81%D0%B5%D1%82%D0%B8/index.xml" rel="self" type="application/rss+xml"/><item><title>Промт-инъекция, видео Карпатого и пара быстрых моделей</title><link>https://tookser.github.io/posts/neural1/</link><pubDate>Sun, 10 Mar 2024 20:36:38 +0300</pubDate><guid>https://tookser.github.io/posts/neural1/</guid><description>Начал проходить курс &amp;ldquo;AI Safety fundamentals&amp;rdquo;, и там есть видео Андрея Карпатого про LLM. Больше половины инфы оттуда я знал, но:
идея про то, что языковые модели как класс программ ведут себя аналогично операционным системам (LLM OS). Подробности по ссылке (видео на английском). там очень классное описание возможных атак на LLM (промт-инъекций и не только), со ссылками на статьи. Понятно, что это всё прикрывается достаточно быстро. Jailbroken: How Does LLM Safety Training Fail?</description><content>&lt;p>Начал проходить курс &amp;ldquo;AI Safety fundamentals&amp;rdquo;, и там есть &lt;a href="https://www.youtube.com/watch?v=zjkBMFhNj_g">видео Андрея Карпатого про LLM&lt;/a>. Больше половины инфы оттуда я знал, но:&lt;/p>
&lt;ul>
&lt;li>идея про то, что языковые модели как класс программ ведут себя аналогично операционным системам (&lt;em>LLM OS&lt;/em>). Подробности по &lt;a href="https://www.youtube.com/watch?v=zjkBMFhNj_g&amp;amp;t=2535s">ссылке&lt;/a> (видео на английском).&lt;/li>
&lt;li>там очень классное описание возможных атак на LLM (промт-инъекций и не только), со ссылками на статьи. Понятно, что это всё прикрывается достаточно быстро.
&lt;ul>
&lt;li>&lt;a href="https://arxiv.org/abs/2307.02483">Jailbroken: How Does LLM Safety Training Fail?&lt;/a>
&lt;ul>
&lt;li>оттуда, например - про base64 кодирование как метод обхода. LLM умеют читать base64, но не защищены.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>ещё пара статей про отдельные виды атак &lt;a href="https://www.youtube.com/watch?v=zjkBMFhNj_g&amp;amp;t=2743s">(ссылка с таймкодом на последнюю часть видео про это)&lt;/a>, в том числе на мультимодальные модели.&lt;/li>
&lt;li>&lt;a href="https://arxiv.org/abs/2307.15043">Universal and Transferable Adversarial Attacks on Aligned Language Models&lt;/a> - про универсальный, выглядящий набором мусора промт-суффикс. Это надо смотреть.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="пара-ныне-недоступных-быстрых-моделей">Пара (ныне недоступных) быстрых моделей&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.ixbt.com/news/2024/02/20/nikomu-neizvestnyj-startap-groq-predstavil-vidimo-luchshij-processor-dlja-vyvoda-nejrosetevyh-modelej.html">Groq (ixbt)&lt;/a> - ASIC (специализированная микросхема) для быстрого инференса LLM. Потыкать можно &lt;a href="https://groq.com">тут,&lt;/a> (там Llama, Mistral, есть платное АПИ), это впечатляет скоростью. В какой-то момент без прокси перестало быть доступным.&lt;/li>
&lt;li>&lt;a href="https://fastsdxl.ai">https://fastsdxl.ai&lt;/a> - это быстрая генерация картинок, со скоростью ввода. Скорость достигнута в т.ч. благодаря использованию маленькой модели SD XL Lightning. Сейчас недоступна, &lt;strong>обещают вернуться.&lt;/strong>&lt;/li>
&lt;/ul></content></item></channel></rss>